# from openai import OpenAI
# import apikey

# # OpenAI API Key
# client = OpenAI(api_key=apikey.api_key)

# # Define the XiYanSQL-style prompt
# nl2sql_template_cn = """ä½ æ˜¯ä¸€å{dialect}ä¸“å®¶ï¼Œç°åœ¨éœ€è¦é˜…è¯»å¹¶ç†è§£ä¸‹é¢çš„ã€æ•°æ®åº“schemaã€‘æè¿°ï¼Œä»¥åŠå¯èƒ½ç”¨åˆ°çš„ã€å‚è€ƒä¿¡æ¯ã€‘ï¼Œå¹¶è¿ç”¨{dialect}çŸ¥è¯†ç”Ÿæˆsqlè¯­å¥å›ç­”ã€ç”¨æˆ·é—®é¢˜ã€‘ã€‚
# ã€ç”¨æˆ·é—®é¢˜ã€‘
# {question}

# ã€æ•°æ®åº“schemaã€‘
# {db_schema}

# ã€å‚è€ƒä¿¡æ¯ã€‘
# {evidence}

# ã€ç”¨æˆ·é—®é¢˜ã€‘
# {question}

# ```sql"""

# # Fill in prompt values
# dialect = "SQLite"  # Change to "MySQL" or "PostgreSQL" as needed
# db_schema = "C:/Users/SIM-PC-1/Desktop/sakila-sqlite3/sakila_master.db"
# question = "movies that are rated PG-13"
# evidence = ""

# prompt = nl2sql_template_cn.format(dialect=dialect, db_schema=db_schema, question=question, evidence=evidence)

# # Call OpenAI API (GPT-4o)
# response = client.chat.completions.create(
#         model="gpt-4o",
#         messages=[
#             {"role": "system", "content": "You are an SQL expert. Generate SQL queries based on the user's request."},
#             {"role": "user", "content": prompt}
#         ],
#         max_tokens=400
#     )

# # Extract the SQL response
# generated_sql = response.choices[0].message.content.strip()

# # Print the generated SQL query
# print("Generated SQL Query:\n", generated_sql)


from openai import OpenAI
import apikey
import os


# OpenAI API Key
client = OpenAI(api_key=apikey.api_key)
dialect = "SQLite"  # Change to "MySQL" or "PostgreSQL" as needed
db_schema = "C:/Users/SIM-PC-1/Desktop/WikiSQL/data/train.db"
question = "What school did Patrick O'Bryant play for?"
evidence = ""

# ğŸŸ¢ Step 1: Schema Linking
schema_linking_prompt = f"""
ä½ æ˜¯ä¸€å{dialect}æ•°æ®åº“ä¸“å®¶ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·é—®é¢˜ï¼Œå¹¶ä»æ•°æ®åº“schemaä¸­æ‰¾åˆ°æœ€ç›¸å…³çš„è¡¨å’Œåˆ—ã€‚

ã€æ•°æ®åº“schemaã€‘
{db_schema}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

è¯·åˆ—å‡ºä¸é—®é¢˜ç›¸å…³çš„è¡¨å’Œåˆ—ï¼š
"""

schema_response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€åSQLä¸“å®¶ï¼Œåˆ†æschemaå¹¶æå–ç›¸å…³è¡¨å’Œåˆ—ã€‚"},
        {"role": "user", "content": schema_linking_prompt}
    ],
    max_tokens=200
)
relevant_schema = schema_response.choices[0].message.content.strip()

# ğŸŸ¢ Step 2: Candidate Generation
candidate_prompt = f"""
åŸºäºä»¥ä¸‹æ•°æ®åº“schemaå’Œç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆå¤šä¸ªå¯èƒ½çš„SQLæŸ¥è¯¢ï¼š

ã€æ•°æ®åº“schemaã€‘
{relevant_schema}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

è¯·ç”Ÿæˆ3ç§å¯èƒ½çš„SQLæŸ¥è¯¢ï¼š
"""
candidate_response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€åSQLä¸“å®¶ï¼Œç”Ÿæˆå¤šä¸ªSQLæŸ¥è¯¢å€™é€‰é¡¹ã€‚"},
        {"role": "user", "content": candidate_prompt}
    ],
    max_tokens=600
)
sql_candidates = candidate_response.choices[0].message.content.strip()

# ğŸŸ¢ Step 3: Candidate Selection
selection_prompt = f"""
ä»¥ä¸‹æ˜¯å¤šä¸ªå¯èƒ½çš„SQLæŸ¥è¯¢ï¼Œè¯·é€‰æ‹©æœ€ç¬¦åˆç”¨æˆ·é—®é¢˜çš„SQLï¼Œå¹¶è¿›è¡Œä¼˜åŒ–ã€‚

ã€SQLå€™é€‰æŸ¥è¯¢ã€‘
{sql_candidates}

è¯·è¿”å›æœ€ä½³SQLæŸ¥è¯¢ï¼š
"""
selection_response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€åSQLä¼˜åŒ–ä¸“å®¶ï¼Œé€‰æ‹©æœ€ä½³SQLã€‚"},
        {"role": "user", "content": selection_prompt}
    ],
    max_tokens=400
)
final_sql = selection_response.choices[0].message.content.strip()

# ğŸ”¥ Output the final optimized SQL query
print("Final Optimized SQL Query:\n", final_sql)
